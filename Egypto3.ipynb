{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "clear all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polars\n",
      "  Using cached polars-1.3.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Using cached polars-1.3.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "Installing collected packages: polars\n",
      "Successfully installed polars-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.24.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorchtools\n",
      "  Using cached pytorchtools-0.0.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached pytorchtools-0.0.2-py2.py3-none-any.whl (3.1 kB)\n",
      "Installing collected packages: pytorchtools\n",
      "Successfully installed pytorchtools-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorchtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6DEZ0S131TIK"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import cv2\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "# from torchsummary import summary\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# import zipfile\n",
    "# import shutil\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go requesting all of my pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "yS5RNX1a1ed-",
    "outputId": "05bfeaf0-d5df-43a2-a87b-b52af675c231"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>filenames</th><th>classes</th><th>bb</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;drive/MyDrive/cropped_pictures…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;drive/MyDrive/cropped_pictures…</td><td>&quot;2&quot;</td><td>&quot;72.0,37.0,236.23839330673218,1…</td></tr><tr><td>&quot;drive/MyDrive/cropped_pictures…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;drive/MyDrive/cropped_pictures…</td><td>&quot;0&quot;</td><td>&quot;0.0,0.0,225.8830212788887,409.…</td></tr><tr><td>&quot;drive/MyDrive/cropped_pictures…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────────────────┬─────────┬─────────────────────────────────┐\n",
       "│ filenames                       ┆ classes ┆ bb                              │\n",
       "│ ---                             ┆ ---     ┆ ---                             │\n",
       "│ str                             ┆ str     ┆ str                             │\n",
       "╞═════════════════════════════════╪═════════╪═════════════════════════════════╡\n",
       "│ drive/MyDrive/cropped_pictures… ┆         ┆                                 │\n",
       "│ drive/MyDrive/cropped_pictures… ┆ 2       ┆ 72.0,37.0,236.23839330673218,1… │\n",
       "│ drive/MyDrive/cropped_pictures… ┆         ┆                                 │\n",
       "│ drive/MyDrive/cropped_pictures… ┆ 0       ┆ 0.0,0.0,225.8830212788887,409.… │\n",
       "│ drive/MyDrive/cropped_pictures… ┆         ┆                                 │\n",
       "└─────────────────────────────────┴─────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs=[pl.read_csv(filename) for filename in glob.glob('/home/jovyan/my_work/Egypto/dfs/dfs/df_*.csv')]\n",
    "df=pl.concat(dfs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>filenames</th><th>classes</th><th>bb</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;425942001_300_300_243_543_empt…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;425942001_300_300_243_543_cara…</td><td>&quot;2&quot;</td><td>&quot;72.0,37.0,236.23839330673218,1…</td></tr><tr><td>&quot;420886001_300_300_1028_1328_em…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;420886001_300_300_1028_1328_ca…</td><td>&quot;0&quot;</td><td>&quot;0.0,0.0,225.8830212788887,409.…</td></tr><tr><td>&quot;423879001_300_300_814_1114_emp…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────────────────┬─────────┬─────────────────────────────────┐\n",
       "│ filenames                       ┆ classes ┆ bb                              │\n",
       "│ ---                             ┆ ---     ┆ ---                             │\n",
       "│ str                             ┆ str     ┆ str                             │\n",
       "╞═════════════════════════════════╪═════════╪═════════════════════════════════╡\n",
       "│ 425942001_300_300_243_543_empt… ┆         ┆                                 │\n",
       "│ 425942001_300_300_243_543_cara… ┆ 2       ┆ 72.0,37.0,236.23839330673218,1… │\n",
       "│ 420886001_300_300_1028_1328_em… ┆         ┆                                 │\n",
       "│ 420886001_300_300_1028_1328_ca… ┆ 0       ┆ 0.0,0.0,225.8830212788887,409.… │\n",
       "│ 423879001_300_300_814_1114_emp… ┆         ┆                                 │\n",
       "└─────────────────────────────────┴─────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.with_columns(pl.col('filenames').str.split('/').list.last())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images=os.listdir('/home/jovyan/my_work/Egypto/Images')\n",
    "existing_files_series = pl.Series(all_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.with_columns(pl.col('filenames').is_in(all_images).alias('new_image')).filter(pl.col('new_image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>filenames</th><th>classes</th><th>bb</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;425942001_300_300_243_543_empt…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;425942001_300_300_243_543_cara…</td><td>&quot;2&quot;</td><td>&quot;72.0,37.0,236.23839330673218,1…</td></tr><tr><td>&quot;420886001_300_300_1028_1328_em…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;420886001_300_300_1028_1328_ca…</td><td>&quot;0&quot;</td><td>&quot;0.0,0.0,225.8830212788887,409.…</td></tr><tr><td>&quot;423879001_300_300_814_1114_emp…</td><td>&quot;&quot;</td><td>&quot;&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────────────────┬─────────┬─────────────────────────────────┐\n",
       "│ filenames                       ┆ classes ┆ bb                              │\n",
       "│ ---                             ┆ ---     ┆ ---                             │\n",
       "│ str                             ┆ str     ┆ str                             │\n",
       "╞═════════════════════════════════╪═════════╪═════════════════════════════════╡\n",
       "│ 425942001_300_300_243_543_empt… ┆         ┆                                 │\n",
       "│ 425942001_300_300_243_543_cara… ┆ 2       ┆ 72.0,37.0,236.23839330673218,1… │\n",
       "│ 420886001_300_300_1028_1328_em… ┆         ┆                                 │\n",
       "│ 420886001_300_300_1028_1328_ca… ┆ 0       ┆ 0.0,0.0,225.8830212788887,409.… │\n",
       "│ 423879001_300_300_814_1114_emp… ┆         ┆                                 │\n",
       "└─────────────────────────────────┴─────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop('new_image')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.with_columns(pl.col('filenames').str.split('_').list.last().str.split('.').list.first().alias('empty')).filter(pl.col('empty')=='caractere').drop('empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY9KTH8OqnM1"
   },
   "source": [
    "We're checkin for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jE6USzWVoo2G",
    "outputId": "5605acd8-32f0-4abd-ebff-cb8257783b49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'425942001_300_300_243_543_caractere.png'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filenames'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34IrzIX8nx82",
    "outputId": "2ef1b64e-2dbd-4b37-d678-636fe890059d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filenames'].value_counts(\n",
    "\n",
    ").filter(pl.col('count')>1\n",
    "         ).with_columns(pl.col('filenames').str.split('_').list.last().str.split('.').list.first().alias('caractere_or_empty')\n",
    "         ).filter(pl.col('caractere_or_empty')=='caractere').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeCVGIItqt-m"
   },
   "source": [
    "droping the duplicates and keeping the last one ( since the photos were probably overwritten because they were assigned the same same )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "03w62VfurEsv"
   },
   "outputs": [],
   "source": [
    "df=df.unique(subset='filenames', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "AKHvU0uG72au"
   },
   "outputs": [],
   "source": [
    "df=df[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEweCw3frNCs",
    "outputId": "45cd38a5-5ec4-40cd-db68-134cee57ba9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34241, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0_2mjxOxoOM"
   },
   "source": [
    "## Customization du dataset [link here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MLin4QClnHNg",
    "outputId": "03c6b083-278b-4711-8e78-d3e2ce9b2f94"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bb'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7TgJ0yFplFmP"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  \"\"\"\n",
    "  This Class creates tensor for each value in a dataframe.\n",
    "  \"\"\"\n",
    "  def __init__(self, df, transform:bool):\n",
    "    \"\"\"\n",
    "      df: dataframe with the annotations\n",
    "    root_dir: directory with all the images\n",
    "    transform: Optionnal transform to apply\n",
    "    \"\"\"\n",
    "\n",
    "    self.df=df\n",
    "    self.transform=transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    # On rajoute le transform, voir ce que ça fait sur les résultats\n",
    "    img_name=self.df['filenames'][idx]\n",
    "    image_file=os.path.join('/home/jovyan/my_work/Egypto/Images',img_name)\n",
    "    image=cv2.imread(image_file)\n",
    "    image=1.6*image - 50\n",
    "    image=image/255\n",
    "\n",
    "    if image is None:\n",
    "      raise FileNotFoundError(f\"Image {img_name} not found\")\n",
    "    if self.transform:\n",
    "      image=self.transform(image)\n",
    "      #On verrifie que 'bb' et 'classes' sont non vides sinon ca risque de buguer\n",
    "    if image is not None:\n",
    "      image = torch.tensor(image, dtype=torch.float32).permute(2,0,1)\n",
    "    bb_str=self.df['bb'][idx]\n",
    "    if bb_str:\n",
    "      bb=list(map(float,self.df['bb'][idx].split(',')))\n",
    "      target=torch.tensor(bb,dtype=torch.float32)\n",
    "    else:\n",
    "      target=torch.tensor([0,0,300,300])\n",
    "    classe_str=self.df['classes'][idx]\n",
    "    if classe_str:\n",
    "        label_map = {'0': 0, '1': 1, '2': 2}\n",
    "        label = torch.tensor(label_map.get(classe_str, -1), dtype=torch.float32)\n",
    "    else:\n",
    "      label = torch.tensor(3, dtype=torch.float32)\n",
    "\n",
    "    return image, target, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PhlVnHXWOJNA"
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "  \"\"\"\n",
    "  This function collates the tensor for them to have the same size\n",
    "\n",
    "  batch: batch in the dataloader\n",
    "  \"\"\"\n",
    "  images, targets, labels = zip(*batch)\n",
    "\n",
    "    # Convert images from numpy arrays to torch tensors if needed\n",
    "  images = [torch.tensor(image) if isinstance(image, np.ndarray) else image for image in images]\n",
    "  images = torch.stack(images, 0)\n",
    "  bbox= [torch.tensor(t) if isinstance(t, np.ndarray) else t for t in targets]\n",
    "  bbox_stacked=torch.stack(bbox,0)\n",
    "  cls= [torch.tensor(c) if isinstance(c, np.ndarray) else c for c in labels]\n",
    "  cls_stacked=torch.stack(cls,0)\n",
    "\n",
    "  return images, bbox_stacked, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_dblgV7Jyoak"
   },
   "outputs": [],
   "source": [
    "train, test= train_test_split(df, test_size=0.3, random_state=42, shuffle=True, stratify=df['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoHsCQxavUfu"
   },
   "source": [
    "penser à changer la typo en snake case et pas en camel_case ( pour les classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5xu93CVSZ_Q-"
   },
   "outputs": [],
   "source": [
    "dataset_train=CustomDataset(train, transform=False )\n",
    "dataset_test=CustomDataset(test, transform=False)\n",
    "dataloader_train=DataLoader(dataset_train, batch_size=16, shuffle=True, collate_fn=custom_collate_fn, num_workers=4)\n",
    "dataloader_test=DataLoader(dataset_test, batch_size=32, shuffle=True, collate_fn=custom_collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DvCwKFvlENG"
   },
   "source": [
    "On se retrouve avec un problème:\n",
    "Les tensor n'acceptent pas des valeurs vides.\n",
    "Donc soit on les remplacent par des valeurs qui ne veulent rien dire, soit on les supprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xF9_U1GPsyR6",
    "outputId": "7df3540a-e430-486f-a6e0-a95cb629a01c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([140.0000,  37.0000, 256.0008, 213.7068])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train:\n",
    "    print(batch[1][0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECePBnfhp-9h",
    "outputId": "a869165e-c21b-43f4-affd-12372b9a6197"
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  This is the model for computer vision\n",
    "  \"\"\"\n",
    "  def __init__(self, num_classes=3, num_bbox_coords=4):\n",
    "    super(VGG16, self).__init__()\n",
    "    self.layer1= nn.Sequential(nn.Conv2d(3,64, (3,3)),\n",
    "                               nn.BatchNorm2d(64),\n",
    "                               nn.ReLU())\n",
    "    self.layer2=nn.Sequential(nn.Conv2d(64,64, (3,3)),\n",
    "                              nn.BatchNorm2d(64),\n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool2d((2,2), stride=2))\n",
    "    self.layer3= nn.Sequential(nn.Conv2d(64,128, (3,3)),\n",
    "                               nn.BatchNorm2d(128),\n",
    "                               nn.ReLU())\n",
    "    self.layer4= nn.Sequential(nn.Conv2d(128,128,(3,3)),\n",
    "                               nn.BatchNorm2d(128),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d((2,2), stride=2))\n",
    "    self.layer5= nn.Sequential(nn.Conv2d(128,256,(3,3)),\n",
    "                               nn.BatchNorm2d(256),\n",
    "                               nn.ReLU())\n",
    "    self.layer6=nn.Sequential(nn.Conv2d(256,256, (3,3)),\n",
    "                              nn.BatchNorm2d(256),\n",
    "                              nn.ReLU())\n",
    "    self.layer7=nn.Sequential(nn.Conv2d(256,256, (3,3)),\n",
    "                              nn.BatchNorm2d(256),\n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool2d((2,2), stride=2, ceil_mode=True))\n",
    "    self.layer8=nn.Sequential(nn.Conv2d(256,512, (3,3)),\n",
    "                              nn.BatchNorm2d(512),\n",
    "                              nn.ReLU())\n",
    "    self.layer9=nn.Sequential(nn.Conv2d(512,512, (3,3)),\n",
    "                              nn.BatchNorm2d(512),\n",
    "                              nn.ReLU(),\n",
    "                             nn.MaxPool2d((2,2),stride=2))\n",
    "    self.layer10=nn.Sequential(nn.Conv2d(512,512, (3,3)),\n",
    "                              nn.BatchNorm2d(512),\n",
    "                              nn.ReLU(),\n",
    "                               nn.MaxPool2d((2,2), stride=2))\n",
    "    self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    self.fc=nn.Sequential(nn.Dropout(0.6),\n",
    "                          nn.Linear(512, 4096),\n",
    "                          nn.ReLU())\n",
    "    self.fc1=nn.Sequential(nn.Dropout(0.6),\n",
    "                           nn.Linear(4096, 4096),\n",
    "                           nn.ReLU())\n",
    "    self.fc_bbox=nn.Linear(4096,num_bbox_coords)\n",
    "    self.fc_class=nn.Linear(4096, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    out=self.layer1(x)\n",
    "    out=self.layer2(out)\n",
    "    out=self.layer3(out)\n",
    "    out=self.layer4(out)\n",
    "    out=self.layer5(out)\n",
    "    out=self.layer6(out)\n",
    "    out=self.layer7(out)\n",
    "    out=self.layer8(out)\n",
    "    out=self.layer9(out)\n",
    "    out=self.layer10(out)\n",
    "    out=self.global_avg_pool(out)\n",
    "    out=out.view(out.size(0), -1)\n",
    "    out=self.fc(out)\n",
    "    out=self.fc1(out)\n",
    "    out_bbox=self.fc_bbox(out)\n",
    "    out_class=self.fc_class(out)\n",
    "    return out_bbox, out_class\n",
    "\n",
    "labels=['class0', 'class1', 'class2']\n",
    "module=VGG16(num_classes=len(labels)).to('cuda')\n",
    "#summary(module, input_size=(3,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Class for Early Stopping the model if it stagnates\n",
    "    \"\"\"\n",
    "    def __init__(self,patience=3, verbose=False, delta=0):\n",
    "        self.patience=patience\n",
    "        self.verbose=verbose\n",
    "        self.counter=0\n",
    "        self.best_score=None\n",
    "        self.early_stop=False\n",
    "        self.val_loss_min=np.Inf\n",
    "        self.delta=delta\n",
    "    \n",
    "    def __call__(self,val_loss,model):\n",
    "        score=-val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score=score\n",
    "        elif score<self.best_score + self.delta:\n",
    "            self.counter+=1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter>=self.patience:\n",
    "                self.early_stop=True\n",
    "        else:\n",
    "            self.best_score=score\n",
    "            self.counter=0\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCaN0z1tmNCY"
   },
   "source": [
    "# On prend la même loss et le même optimizer qu'ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Yr8H3eyh7pFX"
   },
   "outputs": [],
   "source": [
    "loss_fn=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "koPxNa-ciuC4"
   },
   "outputs": [],
   "source": [
    "#optimizer=optim.SGD(module.parameters(), lr=0.01, momentum=0.5)\n",
    "optimizer=torch.optim.Adam(module.parameters(),lr=0.001, weight_decay=1e-4)\n",
    "#scheduler=lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mzbsCjXnrw5B"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def custom_loss_fn(bbox_outputs, class_outputs, bbox_targets, class_number):\n",
    "  \"\"\"This function calculates the loss between the targets and the outputs of the model.\n",
    "  Parameters\n",
    "  ----------\n",
    "  bbox_outputs : _torch tensor_\n",
    "      _bounding box outputs of the model_\n",
    "  class_outputs : _torch tensor_\n",
    "      _class outputs of the model_\n",
    "  bbox_targets : _torch tensor_\n",
    "      _bounding box targets_\n",
    "  class_number : _torch tensor_\n",
    "      _class targets_\n",
    "\n",
    "  Returns the loss\n",
    "  \n",
    "  _torch tensors_\n",
    "      _the total loss, the loss for the bounding boxes and the loss for the classes_\n",
    "  \"\"\"\n",
    "    bbox_targets = torch.stack([b for b in bbox_targets])\n",
    "    if class_outputs.dtype != torch.float:\n",
    "      class_outputs = class_outputs.float()\n",
    "\n",
    "    bbox_loss = F.smooth_l1_loss(bbox_outputs, bbox_targets, reduction='mean')\n",
    "    class_loss = loss_fn(class_outputs, class_number)\n",
    "    total_loss = bbox_loss + class_loss\n",
    "    return total_loss, bbox_loss, class_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LcwjB-gmkBIy"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer,total_correct, total_samples):\n",
    "    \"\"\"This function trains one epoch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch_index : _int_\n",
    "    tb_writer : _path_\n",
    "        _path for writing the model advances_\n",
    "    total_correct : _int_\n",
    "        _number of correct predictions for classes_\n",
    "    total_samples : _int_\n",
    "\n",
    "    Returns the train loss after 1000 batchs\n",
    "    -------\n",
    "    \"\"\"\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, (image, bbox, classe) in enumerate(dataloader_train):\n",
    "        # Putting each targets into the same device\n",
    "        inputs=image.to(\"cuda\")\n",
    "        bbox_targets = [b.to(\"cuda\") for b in bbox]\n",
    "        classe=np.asarray(classe)\n",
    "        class_targets=torch.tensor(classe,dtype=torch.int64).to(\"cuda\")\n",
    "        # Calculating the losses with the outputs\n",
    "        bbox_outputs, class_outputs = module(inputs)\n",
    "        _,predictions=torch.max(class_outputs,1)\n",
    "        total_correct+=(predictions==class_targets).sum().item()\n",
    "        total_samples+=class_targets.size(0)\n",
    "        loss, bbox_loss, class_loss = custom_loss_fn(bbox_outputs, class_outputs, bbox_targets, class_targets)\n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        #Observing the advances after 1000 batchs\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print('batch {} loss: {}'.format(i+1, last_loss))\n",
    "            tb_x = epoch_index * len(dataloader_train) + i + 1\n",
    "            #tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0\n",
    "            accuracy=100*total_correct/total_samples\n",
    "            # On peut essayer de mesurer la distance entre ce qui est prédit et la vraie bounding box \n",
    "            distance=bbox_targets[-1]-bbox_outputs[-1]\n",
    "            print('distance:',distance)\n",
    "            print('batch{} acc: {}'.format(i+1, accuracy))\n",
    "            print(bbox_loss, class_loss)\n",
    "    #scheduler.step()\n",
    "    return last_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGug99PWtoB-",
    "outputId": "e5630953-7e03-42b3-e989-51e9eeb5c5aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH1\n",
      "batch 1000 loss: 37.615050241470335\n",
      "distance: tensor([-109.5843,   -4.6337,  -26.2985,   30.1387], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 35.1375\n",
      "tensor(37.1565, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(1.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  3%|▎         | 1/30 [03:51<1:52:02, 231.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 39.44320062299231\n",
      "LOSS train 37.615050241470335 valid 31.65104866027832\n",
      "EPOCH2\n",
      "batch 1000 loss: 31.76504083824158\n",
      "distance: tensor([  8.7744, -37.8248,   8.3383,  65.4574], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 44.1625\n",
      "tensor(32.6686, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(1.3324, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  7%|▋         | 2/30 [07:41<1:47:33, 230.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 47.25007300691132\n",
      "LOSS train 31.76504083824158 valid 28.000389099121094\n",
      "EPOCH3\n",
      "batch 1000 loss: 26.500612679481506\n",
      "distance: tensor([-13.9295,   6.4663,  57.6741,  20.9532], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 63.275\n",
      "tensor(22.8874, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.9495, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|█         | 3/30 [11:32<1:43:51, 230.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 57.52944612089944\n",
      "LOSS train 26.500612679481506 valid 31.62297821044922\n",
      "EPOCH4\n",
      "batch 1000 loss: 22.613471733093263\n",
      "distance: tensor([-25.5337,  -3.6813,  -4.8819,  15.7870], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 74.51875\n",
      "tensor(24.5776, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(1.2171, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 13%|█▎        | 4/30 [15:24<1:40:08, 231.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 64.3434245108537\n",
      "LOSS train 22.613471733093263 valid 18.514490127563477\n",
      "EPOCH5\n",
      "batch 1000 loss: 20.136230697631834\n",
      "distance: tensor([ 87.3868,  -0.6724,  21.0272, -36.6001], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 81.48125\n",
      "tensor(15.4468, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 17%|█▋        | 5/30 [19:15<1:36:19, 231.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 92.426749732308\n",
      "LOSS train 20.136230697631834 valid 13.467353820800781\n",
      "EPOCH6\n",
      "batch 1000 loss: 17.87041598892212\n",
      "distance: tensor([-15.9559, -35.7854, -15.5966, -16.2199], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 86.7875\n",
      "tensor(20.2667, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.6827, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|██        | 6/30 [23:06<1:32:26, 231.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 93.34176968753042\n",
      "LOSS train 17.87041598892212 valid 12.906185150146484\n",
      "EPOCH7\n",
      "batch 1000 loss: 16.881983563423155\n",
      "distance: tensor([ -7.0496,   2.2424, -19.6395,   3.8112], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 89.575\n",
      "tensor(13.4433, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.8854, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 7/30 [26:57<1:28:34, 231.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 92.91346247444758\n",
      "LOSS train 16.881983563423155 valid 12.692296028137207\n",
      "EPOCH8\n",
      "batch 1000 loss: 15.595356362342834\n",
      "distance: tensor([17.3941,  3.6683,  2.9009, -3.7599], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 92.1125\n",
      "tensor(12.6011, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.1526, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 27%|██▋       | 8/30 [30:48<1:24:42, 231.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 94.65589409130732\n",
      "LOSS train 15.595356362342834 valid 13.059775352478027\n",
      "EPOCH9\n",
      "batch 1000 loss: 14.275630776405334\n",
      "distance: tensor([ 8.7464, 12.1114, 15.2978, 30.8583], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 93.4375\n",
      "tensor(10.0478, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|███       | 9/30 [34:39<1:20:53, 231.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 96.61247931470847\n",
      "LOSS train 14.275630776405334 valid 10.434185028076172\n",
      "EPOCH10\n",
      "batch 1000 loss: 13.103003793239594\n",
      "distance: tensor([ -8.0803,  -4.1626,  11.8299, -14.9653], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 94.55625\n",
      "tensor(11.5561, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.4989, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 33%|███▎      | 10/30 [38:31<1:17:04, 231.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 96.13550082741166\n",
      "LOSS train 13.103003793239594 valid 13.610391616821289\n",
      "EPOCH11\n",
      "batch 1000 loss: 11.715950258731842\n",
      "distance: tensor([ -2.7265,  -0.8449,  -8.6451, -11.8125], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 94.8\n",
      "tensor(12.1696, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 37%|███▋      | 11/30 [42:22<1:13:13, 231.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 94.46120899445147\n",
      "LOSS train 11.715950258731842 valid 8.183693885803223\n",
      "EPOCH12\n",
      "batch 1000 loss: 10.615579411029815\n",
      "distance: tensor([  7.0923,  -2.4799, -12.4600,   5.2257], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 95.74375\n",
      "tensor(7.6298, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|████      | 12/30 [46:13<1:09:19, 231.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 98.39384795093936\n",
      "LOSS train 10.615579411029815 valid 6.086190700531006\n",
      "EPOCH13\n",
      "batch 1000 loss: 9.98658387708664\n",
      "distance: tensor([-13.7591,   0.1312,   0.6704, -16.5088], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 96.68125\n",
      "tensor(8.2636, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 43%|████▎     | 13/30 [50:04<1:05:30, 231.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 97.92660371848535\n",
      "LOSS train 9.98658387708664 valid 8.409052848815918\n",
      "EPOCH14\n",
      "batch 1000 loss: 9.244005799293518\n",
      "distance: tensor([-25.7540,   1.4477,   1.0528,  24.8931], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 96.96875\n",
      "tensor(8.5734, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 47%|████▋     | 14/30 [53:54<1:01:35, 230.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 98.05314903144165\n",
      "LOSS train 9.244005799293518 valid 6.138607978820801\n",
      "EPOCH15\n",
      "batch 1000 loss: 8.694130918979646\n",
      "distance: tensor([29.7932, -3.6461,  3.7269,  7.4622], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 97.78125\n",
      "tensor(9.9648, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0604, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████     | 15/30 [57:46<57:46, 231.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.1628540835199\n",
      "LOSS train 8.694130918979646 valid 9.273397445678711\n",
      "EPOCH16\n",
      "batch 1000 loss: 8.451806876659393\n",
      "distance: tensor([ -3.4062,   0.8003, -16.4865, -33.7204], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 98.13125\n",
      "tensor(7.6358, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 53%|█████▎    | 16/30 [1:01:37<53:57, 231.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.80531490314416\n",
      "LOSS train 8.451806876659393 valid 4.344549179077148\n",
      "EPOCH17\n",
      "batch 1000 loss: 7.990671293735504\n",
      "distance: tensor([ 3.6681,  0.6404, 22.8537,  7.5594], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 98.43125\n",
      "tensor(5.9312, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(4.3532e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 57%|█████▋    | 17/30 [1:05:29<50:05, 231.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.06551153509199\n",
      "LOSS train 7.990671293735504 valid 5.3762030601501465\n",
      "EPOCH18\n",
      "batch 1000 loss: 7.715450277090072\n",
      "distance: tensor([ 4.2390,  0.2694, -0.6912,  8.5578], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 98.6125\n",
      "tensor(5.9446, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████    | 18/30 [1:09:19<46:13, 231.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.766377883773\n",
      "LOSS train 7.715450277090072 valid 4.055408477783203\n",
      "EPOCH19\n",
      "batch 1000 loss: 7.416149864196777\n",
      "distance: tensor([ 0.7120, -1.3511,  8.4219, -3.3203], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 98.68125\n",
      "tensor(5.6650, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(9.3132e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 63%|██████▎   | 19/30 [1:13:11<42:22, 231.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.55222427723157\n",
      "LOSS train 7.416149864196777 valid 5.921968936920166\n",
      "EPOCH20\n",
      "batch 1000 loss: 7.333511281967163\n",
      "distance: tensor([ 7.8722,  2.3912, -2.8704,  7.7802], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 98.60625\n",
      "tensor(8.3302, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.2506, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 67%|██████▋   | 20/30 [1:17:02<38:31, 231.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.8734546870437\n",
      "LOSS train 7.333511281967163 valid 4.2989397048950195\n",
      "EPOCH21\n",
      "batch 1000 loss: 7.1199584474563595\n",
      "distance: tensor([ 1.5459, -0.4402, 12.7122, 10.3234], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 98.9125\n",
      "tensor(7.7608, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(5.1837e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|███████   | 21/30 [1:20:53<34:41, 231.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.43541321911808\n",
      "LOSS train 7.1199584474563595 valid 3.477137327194214\n",
      "EPOCH22\n",
      "batch 1000 loss: 6.842664168596268\n",
      "distance: tensor([ 4.8679,  0.3738, -7.4666, -3.5804], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 98.9625\n",
      "tensor(5.7134, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(3.3080e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 73%|███████▎  | 22/30 [1:24:44<30:47, 230.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.81504915798696\n",
      "LOSS train 6.842664168596268 valid 4.107247352600098\n",
      "EPOCH23\n",
      "batch 1000 loss: 6.688384718894959\n",
      "distance: tensor([-0.1012,  0.5254, -3.2544,  4.0527], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 99.06875\n",
      "tensor(6.6491, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 77%|███████▋  | 23/30 [1:28:35<26:56, 230.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.81504915798696\n",
      "LOSS train 6.688384718894959 valid 3.5164060592651367\n",
      "EPOCH24\n",
      "batch 1000 loss: 6.531451442003251\n",
      "distance: tensor([-5.0906, -1.6804, -4.6560, -3.6646], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 98.91875\n",
      "tensor(5.6536, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(9.6857e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|████████  | 24/30 [1:32:25<23:04, 230.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.7566436289302\n",
      "LOSS train 6.531451442003251 valid 3.6776251792907715\n",
      "EPOCH25\n",
      "batch 1000 loss: 6.479969624757767\n",
      "distance: tensor([-8.8468,  1.9317, 15.5202, 28.8851], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 99.13125\n",
      "tensor(7.0202, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(7.9046e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 83%|████████▎ | 25/30 [1:36:16<19:14, 230.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.9902657451572\n",
      "LOSS train 6.479969624757767 valid 3.636195659637451\n",
      "EPOCH26\n",
      "batch 1000 loss: 6.256730501174927\n",
      "distance: tensor([-7.5379, -2.2256, -8.8742, -9.9731], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 99.225\n",
      "tensor(6.4518, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 87%|████████▋ | 26/30 [1:40:08<15:24, 231.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.90265745157208\n",
      "LOSS train 6.256730501174927 valid 3.7228808403015137\n",
      "EPOCH27\n",
      "batch 1000 loss: 6.2036077876091005\n",
      "distance: tensor([ 6.0302,  1.0794, 10.1387, 16.9531], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 99.225\n",
      "tensor(6.4211, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████ | 27/30 [1:44:00<11:34, 231.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.66903533534509\n",
      "LOSS train 6.2036077876091005 valid 3.7357916831970215\n",
      "EPOCH28\n",
      "batch 1000 loss: 6.102120569467544\n",
      "distance: tensor([ 2.5000,  1.4583, -1.1575, -2.0983], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 99.29375\n",
      "tensor(6.8654, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0385, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 93%|█████████▎| 28/30 [1:47:51<07:42, 231.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.96106298062884\n",
      "LOSS train 6.102120569467544 valid 3.453482151031494\n",
      "EPOCH29\n",
      "batch 1000 loss: 5.990585672140122\n",
      "distance: tensor([-8.9651,  0.0800,  5.5604, -0.6575], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 99.325\n",
      "tensor(5.4739, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(1.1921e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 97%|█████████▋| 29/30 [1:51:42<03:51, 231.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.74690937408741\n",
      "LOSS train 5.990585672140122 valid 2.940260171890259\n",
      "EPOCH30\n",
      "batch 1000 loss: 5.941450531244278\n",
      "distance: tensor([ 1.1582,  0.7421, 24.3809, 17.0001], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "batch1000 acc: 99.26875\n",
      "tensor(5.9299, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:55:33<00:00, 231.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 99.98053149031442\n",
      "LOSS train 5.941450531244278 valid 3.477871894836426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping()\n",
    "timestamp=datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "log_file='log_trains_1'\n",
    "#os.makedirs(log_file)\n",
    "writer=SummaryWriter(log_file.format(timestamp))\n",
    "epoch_number=0\n",
    "EPOCHS=30\n",
    "best_v_loss=1\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "  total_correct=0\n",
    "  total_samples=0\n",
    "  total_v_correct=0\n",
    "  total_v_samples=0    \n",
    "  print('EPOCH{}'.format(epoch_number + 1))\n",
    "  module.train(True)\n",
    "  #Allowing to clear space for better memory management\n",
    "  torch.cuda.empty_cache()\n",
    "  avg_loss=train_one_epoch(epoch_number,writer, total_correct, total_samples)\n",
    "  torch.cuda.empty_cache()\n",
    "  #print(f\"everything works for avg_loss\")\n",
    "\n",
    "  running_vloss=0\n",
    "  module.eval()\n",
    "#Evaluating the model for each epoch\n",
    "  with torch.no_grad():\n",
    "      \n",
    "    for i,(vimages, vbbox, vclass) in enumerate(dataloader_test):\n",
    "      vinputs= vimages.to(\"cuda\")\n",
    "      vbbox_target=[b.to(\"cuda\") for b in vbbox]\n",
    "      vclass_targets=np.asarray(vclass)\n",
    "      vclass_target=torch.tensor(vclass_targets, dtype=torch.int64).to(\"cuda\")\n",
    "      voutputs_bbox, voutputs_class=module(vinputs)\n",
    "      _,v_predictions=torch.max(voutputs_class,1)\n",
    "      total_v_correct+=(v_predictions==vclass_target).sum().item()\n",
    "      total_v_samples+=vclass_target.size(0)\n",
    "      vloss, vbbox_loss, vclasse_loss =custom_loss_fn(voutputs_bbox, voutputs_class, vbbox_target, vclass_target)\n",
    "      running_vloss+=vloss\n",
    " #Priting the accuracy \n",
    "  v_accuracy=100*total_v_correct/total_v_samples\n",
    "  print(f'validation acc: {v_accuracy}')\n",
    "#Printing train losses and validation losses\n",
    "  avg_vloss=running_vloss/(i+1)\n",
    "  print('LOSS train {} valid {}'.format(avg_loss, avg_vloss ))\n",
    "  writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "  writer.flush()\n",
    "  early_stopping(avg_vloss, module)\n",
    "    # Track best performance, and save the model's state\n",
    "  if avg_vloss < best_v_loss:\n",
    "      best_vloss = avg_vloss\n",
    "      model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "      torch.save(module.state_dict(), model_path)\n",
    "\n",
    "  epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.state_dict()\n",
    "torch.save(module.state_dict(), 'module.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
